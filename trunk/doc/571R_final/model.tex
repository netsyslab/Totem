\subsection{Communication-to-Computation Ratio in a Cluster Setup}
\label{sec:model}
We first present the assumptions used in the calculation; then, based on these assumptions, we provide an estimate of the computation-to-communication ratio. 

Let $n$ be the number of compute nodes in a cluster, and $v$ be the number of vertices in a graph. We assume the following:
\begin{enumerate}
\item The processing model is assumed to be Bulk Synchronous Parallel (BSP). Based on this model, the processing is divided into two phases, computation and communication; hence allowing for batch communication.

\item The compute nodes are connected via 10Gbps links. This is a reasonable assumption as 10Gbs links have become commodity. Due to various overheads, however, a 10GBps link do not perform at peak rate. Feng et al. \cite{Feng2003} reports that in a commodity setup, a 10Gbps Ethernet link can perform at 8Gbps. Moreover, in the communication phase, all nodes communicate at the same time, hence we assume that half of a node's bandwidth is dedicated for sending and the other for receiving. Accordingly, we assume a node's link throughput to be 8/2 = 4Gbps. Finally, since communication happens in batches, we discard the link latency.

\item The compute nodes have dual socket quad core Nehalem processors similar to the setup described in \S~\ref{sec:evaluation}. This is an optimistic assumption as this represents high-end commodity components.

\item The graph is partitioned such that each compute node holds an equal number of vertices $\frac{v}{n}$ vertices.

\item The size of a message communicated per vertex is 4 bytes (e.g., the level in BFS, the rank in PageRank and the distance in Dijkstra).

\item The graph size is set according to Graph500 specifications ~\cite{graph500}: if $v$ is number of vertices in the graph, then the number of edges is $16 \times v$.

\item All the neighbors of a vertex do not exist in that vertex's partition (i.e., all neighbor exist in remote partitions). This is a conservative assumption as it increases the communication overhead. In the following, we discuss a parameter that will help us estimate the amount of data each compute node communicates. Let $\beta$ be a number between 0 and 1 that represents the fraction of partitions (i.e., compute nodes) where a vertex has at least one neighbor. $\beta$ can be approximated by looking at graph characteristics. Graph500 specification assumes scale-free graphs, where degree distribution follows power law; hence, most of the vertices has relatively low degree (i.e., few neighbors). Accordingly, we approximate $\beta$ as $\frac{k}{n}$, where $k$ is the third quantile of degree distribution of the graph. If we consider a toy class graph, the third quantile is approximately 5, hence $\beta = \frac{5}{n}$. We don't expect this to change for a larger class.

\item The graph processing rate of a compute node is that of the one achieved for the LiveJournal workload. This is an optimistic assumption because the graph is relatively small, and its vertex array fits the cache of a commodity compute node. The compute rates for this graph based on the evaluation in \S~\ref{sec:evaluation} is roughly: BFS = 256ME/s.
\end{enumerate}

Consider a BFS algorithm. In BFS each vertex level is communicated at most once (when it is part of the frontier).  Hence, each compute node will communicate the level of each of its vertices to $\beta \times n$ nodes, and the total amount of data communicated is $\frac{\beta n v}{n}$ =  $\beta v$ units. 

Hence, the communication time is $\frac{(\beta v \times 4Bytes)}{(4 \times 128MBytes/second)} = \frac{5 \times v}{128M \times n}$ seconds, and the computation time is $\frac{v \times 16}{256M \times n} = \frac{v}{16M \times n}$ seconds. Therefore, the computation-to-communication ratio is $\frac{v}{16M \times n} \times \frac{128M \times n}{5 \times v} = 1.6$. This means that the computation phase occupies over 61\% of the time, and that accelerating this phase would improve the end-to-end performance of the system. Note that the estimate here is conservative, hence we expect the computation time to be even higher in reality.
