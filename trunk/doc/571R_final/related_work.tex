\section{Related Work}
\label{sec:related}

This project spans the following areas: graph algorithms, in general, and parallel graph algorithms, in particular; graph algorithms on GPUs; and parallel graph processing frameworks. This section briefly comments on the related literature collected so far.

{\bf Parallel graph algorithms.} Although graph algorithms are a well studied area, leveraging parallel architecture to accelerate the algorithm runtime is far from straightforward task. A parallel implementation may require substantial changes to the original sequential algorithm and strong assumptions about the parallel platform. The required changes and assumptions come at the expense of making the algorithm less portable across platforms.

Although the PRAM~\cite{Fortune78} parallel processing model is vastly used in the study of parallel algorithms~\cite{Quinn1984,Atallah1984}, some recent works try to provide performance analysis on distributed memory machines models. Meyer and Sanders~\cite{Meyer2003}, for example, gives a parallel algorithm for single source shortest path named $\Delta$-stepping. The authors analyze the performance of the algorithm in the PRAM model and provide extensions to distributed memory model. The algorithm works by keeping nodes with tentative distances in separate buckets where each bucket represent the distances within the range of size $\Delta$. In each phase the algorithm consider the nodes in the non-empty buckets and edges of weight up to $\Delta$. Parallelism is achieved by processing the nodes in a given bucket concurrently. 

{\bf Graph algorithms on GPUs.} Previous work investigates the use of GPUs to accelerate graph computation~\cite{Harish2007, Katz2008, Sungpack2010, dehne2010exploring}. For example, Sungpack et al. ~\cite{Sungpack2010} shows that, in the case of breadth-first search, a single Nvidia Tesla GPU offers up to 2.5x speedup compared to dual socket, quad-core Intel Xeon symmetric multiprocessor on realistic workloads. However, those works focus on few graph algorithms, mainly breadth-first search, single source shortest path, and all pairs shortest path. Moreover, the implementations assume that the graph fits GPU memory, which puts a limitation on the size of graphs that can be processed. 

A natural scaling path is to run large graph algorithms into multi-GPU systems. Katz et al. ~\cite{Katz2008} implement a hand-crafted version of all pairs shortest path algorithm for multi-GPU systems. However, the proposed approach is tightly coupled with the problem and cannot be generalized to other algorithms. Additionally, the implementation provided by Katz et al. assumes an adjacency matrix graph representation that imposes a significant space overhead for sparse graphs, a characteristic that is common in the majority of real-world graphs. Yet another, nevertheless fundamental, challenge to harness multi-GPU systems is to adapt these algorithms from the PRAM model to a distributed memory machines model such as BSP or LogP. Gerbessiotis and Valiant provide results on the performance impact on emulating a DMM model with PRAM~\cite{Gerbessiotis92}. 

{\bf Graph processing frameworks.} The Parallel BGL~\cite{gregor2005parallel} and Pregel~\cite{Malewicz2009} present frameworks to implement distributed graph algorithms. Both frameworks specify generic concepts for designing distributed graph algorithms. The frameworks are based on abstractions that are common among graph algorithms. Examples of such abstractions include vertices, edges, property maps {\em (key-value pairs)}, and mechanisms for data propagation and graph traversal. 

It is worth noting that PBGL, Pregel, and others~\cite{Zhao2009} assume traditional cluster systems (i.e., nodes connected via network and containing traditional multi-core processors). This work targets, on the other hand, GPU-based systems, which have different computational model and offer different trade-offs and challenges. 

To the best of our knowledge, there is no graph processing framework optimized for hybrid GPU-based platforms. A framework specialized for GPU-based platforms could offer optimizations to minimize communication overhead over the GPU's high-latency I/O channels (e.g., employing compact messaging and graph representations to minimize communication and space footprint); also it could offer graph-specific abstractions that hide the GPU's complex memory model while efficiently leveraging it (e.g., transparently utilizing shared memory). 

