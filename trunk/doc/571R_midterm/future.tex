\section{Future Work}
\label{sec:future}

Implementing these {\sc bfs}, Dijkstra's algorithm, and PageRank already helped to identify the commonalities among graph algorithms. For example, operations that sweep through the list of neighbors of each vertex are present in all three algorithms. Therefore, defining common building-block kernels that can be used by a variety of graph algorithms is clearly a potential way to go. Additionally, and equally important, there are logistics operation such as graph parsing and initialization, memory allocation, and data transfer routines that can also be part of an infrastructure shared by all the algorithms. In fact, some of these operations are already provided as abstractions in the current version of {\sc totem}.

Besides the abstractions that are undoubtedly useful in CPU-single-GPU hybrid platforms, it is also necessary to study and design new abstractions for a multi-GPU environment. To this end, we will first investigate the potential losses in performance due to the mismatch between the parallel programming model assumed by the algorithms (i.e., PRAM) and the model that best match a multi-GPU platform (e.g., BSP). This effort can benefit from previous studies on the translation of parallel algorithms from on model to another~\cite{Gerbessiotis92}. 

Finally, it is also important to show benefits at the application layer. Therefore, we consider a list of candidate applications that could provide evidence of {\sc Totem}'s applicability and good estimates of the application-level performance that {\sc Totem} can deliver. 

{\bf Community detection.} Online social systems are commonplace nowadays. Graphs are unsurprisingly the mathematical abstraction of choice to study the characteristics of user interactions. One important application is the detection of subgroups of users where the connections are stronger within the group than those to individuals outside the group. This application is called {\em community detection} and due to the scale of existing social networks, demands efficient and scalable solutions. This application is a good candidate as it may build upon the already implemented algorithms (e.g., Girwan-Newman's community detection algorithm~\cite{Newman2004} which is based on a centrality measure that uses {\sc bfs}).

{\bf Characterization of time-evolving social networks.} Although online social networks are inherently dynamic (i.e., users are actively exchanging public/private messages, producing and consuming content), the vast majority of studies that analyze such network focus on static snapshots of the network~\cite{Willinger2009}, specially due to the computational cost of analysing large networks while considering their time-evolving characteristics. Thus, we plan to use {\sc Totem} to enable the characterization of structural aspects of dynamic online social networks. In particular, we focus on the following question: what is the rate of variation in node centrality measures in a network with time-evolving edge weights? This study can also leverage already implemented algorithms by extending them to compute centrality measures efficiently.

{\bf Genome Assembly.} Determining the order of nucleotides in a DNA molecule, a process named sequencing, is an essential process in biosciences research and discovery. Recently, with the emergence of new high-throughput sequencing technologies, DNA sequencing machines have become commodity~\cite{venter2010multiple}, while, at the same time, offering drastic improvements in sequencing rates: new sequencing machines, such as the ones offered by 454 life sciences and Illumina, can generate almost 100 billion nucleotides per day per machine, which is 50,000 times faster than ten years ago.

One of the challenges presented by new sequencing technologies is that they produce much shorter read sequences compared to old sequencing technologies. Traditional genome assemblers (such as the Celera assembler) were not designed to work with such data characteristics. New assemblers such as Velvet~\cite{Zerbino2008} and Euler~\cite{pevzner2001eulerian} address this challenge by modelling the problem as constructing and traversing a de Bruijn graph of the read sequences. However, those tools are sequential and do not scale in terms of both performance and size (i.e., large mammalian-sized genomes).
In this context, another target application is the construction of De Brujin graphs and the computation of Eulerian tours~\cite{Atallah1984} in such graphs. De Brujin graphs are used to model one of the most important bioinformatics procedures named genome assembly, and computing the Eulerian tour is an essential phase in this process~\cite{pevzner2001eulerian, zerbino2008velvet}.